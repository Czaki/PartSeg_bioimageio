{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer\n",
    "In this tutorial we show how to train deep learning model for improving data labeling based on outputs from previous PartSeg analyses. In this version, we are using publicly available infrastructure in the Google Colab environment. Using local computational services is covered in `train_model_server.md`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to improve data labeling using deep learning on PartSeg output\n",
    "\n",
    "Assumption for this tutorial is that the user has output of (semi)automatic segmentation methods which will be used for training of a new deep learning model.\n",
    "\n",
    "PartSeg provides several (semi)automatic segmentation methods (see red box in Fig. below). They can segment an input dataset, but achieving the best results requires human supervision. For example, the `Gauss noise filtering` method requires the user to select a Gauss radius and whether the Gauss will be calculated per layer or on the whole image. Another example would be parititioning the dataset into high/low noise parts and using different methods for both partitions.\n",
    "\n",
    "In cases where similar experiments are often repeated on different input sets, machine learning or deep learning methods can be trained and are likelly to be successfull in automating future experiments. This of course requires collecting some training data, which for example can come from previous experiments.\n",
    "\n",
    "In this tutorial we present how the user could use the output from previous segmentations done with PartSeg, which included `Gauss noise filtering` step, to train a deep-learning model. Then the user could add such a model to PartSeg and use it in a fully automated way to segment similar datasets from the GUI interface and do measurements in PartSeg to extract knowledge about the segmentation results.\n",
    "\n",
    "![](images/marked_methods.png)\n",
    "\n",
    "<!-- There are multiple scenarios when having a working deep learning model could help:\n",
    "\n",
    "1) Used (semi)automatic method requires using a given probe or marking objects that are not required in the experiment. Then Segmentation could be done on specially prepared data, but a model train only using the subset of channels. Because some methods have a limited number of channels, it may allow marking and investigating more objects important from the point of scientific question. For example, confocal microscopes allow using only four channels.\n",
    "\n",
    "2) Sometimes, an available method requires some expensive (in the context of time) preprocessing steps like deconvolution.\n",
    "\n",
    "3) Collecting data with a low noise ratio may require access to limited and expensive infrastructure. However, collecting only data needed for the model training may be much more straightforward than collecting all experiment data. Then, the preprocessing phase could add artificial noise before starting the train. -->\n",
    "\n",
    "The data sets for this tutorial are available on [Zenodo](https://zenodo.org/record/7335430). There are multiple ways to share data. In this tutorial we recommend Zenodo. It has the following advantages:\n",
    "\n",
    "1) It is hostted by CERN with a guarantee of long time persistence.\n",
    "2) The entries are versioned so it is possible to update dataset and at the same time keep access to the previous version which is crucial for reproducible science. \n",
    "2) Each entry gets DOI, so it is possible to cite it easily. There is one DOI that always points to the newest version, but also, each version has its own DOI.\n",
    "4) The default maximum dataset size is 50GB, but the Zenodo team could increase it on request. \n",
    "\n",
    "For training machine learning models to produce the best results on future data, i.e., to generalise well, it is important to split the input data into two parts *Train* and *Test* sets. The *Train* set size should be 80-90% of the data, and *Test* should contain 10-20%. Such an approach allows to counteract model overfitting, i.e., obtaining models adapted too much to the particular input data set and performing much worse in general. It is also important that neither the *Train* nor *Test* data contain errors or omissions. The sample data we provid in this tutorial is already cleaned and appropriately split. There are three folders, which the reader is encouraged to inspect:\n",
    "\n",
    "* *Train* - the *Train* set,\n",
    "* *Test* - the *Test* set,\n",
    "* *Problematic* - data with a high number of artifacts.\n",
    "\n",
    "Each folder contains PartSeg projects with images and segmentations. The raw data on which this dataset is built on is also available on [zenodo](https://zenodo.org/record/7335168).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab\n",
    "\n",
    "Run the following code only if executing notebook on Google Colab to setup the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make sure that you are using a GPU. For this, go to:\n",
    "# Runtime->Change runtime type and select Hardware accelarator->GPU\n",
    "# When you then run this cell you should see a gpu status overview\n",
    "# (if something went wrong you will see an error message)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install conda in your google drive session\n",
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workaround for bug in conda-forge\n",
    "!ln -s /usr/lib/x86_64-linux-gnu/libfontconfig.so.1 /usr/lib/libfontconfig.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update mamba\n",
    "!mamba update mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required libraries\n",
    "!mamba install -y -c pytorch -c conda-forge python-elf dask bioimageio.core PartSeg==0.14.6 npe2==0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-deps kornia\n",
    "!pip install --no-deps git+https://github.com/constantinpape/torch-em\n",
    "!pip install --no-deps git+https://github.com/PartSeg/PartSeg_bioimageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_PATH = \"exports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount your google drive to permanently save data\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")\n",
    "EXPORT_PATH = \"/content/gdrive/MyDrive/exports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = os.path.join(\"data\", \"neu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download data from zenodo please execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import zipfile\n",
    "import tempfile\n",
    "from urllib import request\n",
    "\n",
    "def download_and_unpack_data():\n",
    "    if os.path.exists(data_path) and os.listdir(data_path):\n",
    "        return\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        print(temp_dir)\n",
    "        zip_path = os.path.join(temp_dir, \"ecoli_neu_PartSeg_projects.zip\")\n",
    "        request.urlretrieve(\"https://zenodo.org/record/7335430/files/ecoli_neu_PartSeg_projects.zip?download=1\", zip_path)\n",
    "        os.makedirs(data_path)\n",
    "        with zipfile.ZipFile(zip_path) as zip_ref:\n",
    "            zip_ref.extractall(data_path)\n",
    "\n",
    "download_and_unpack_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It this tutorial we use [torch_em](https://github.com/constantinpape/torch-em) as a wrapper around [pytorch](https://pytorch.org/). Please read its installation [instructions](https://github.com/constantinpape/torch-em#installation). To keep readability of this document part of code is mooved out to `PartSeg_bioimageio.train_util` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch_em.transform\n",
    "from torch_em.model import UNet2d\n",
    "\n",
    "from PartSeg_bioimageio.train_util import get_partseg_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_DEPTH=4\n",
    "NETWORK_INITIAL_FEATURES=32\n",
    "PATCH_SIZE=256\n",
    "BATCH_SIZE=8\n",
    "ITERATIONS=500\n",
    "SAVE_ROOT=\"./checkpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PartSeg allows for ROI Extraction (Data labeling) algorithm to return multiple labelings of data for better visualization. The required one is \"ROI\" in which each component is marked with separate number.\n",
    "\n",
    "In the [Trapalyzer](https://github.com/Czaki/Trapalyzer) that is used for generate labeling in this project following additional labeling are provided:\n",
    "\n",
    "* PMN neu: polymorphonuclear, unstimulated neutrophils,\n",
    "* RND neu: cells with decondensed chromatin and rounded nucleus,\n",
    "* RUP neu: neutrophils with ruptured nuclear envelope,\n",
    "* PER neu: neutrophils with a permeabilized plasma membrane,\n",
    "* Bacteria: e-coli bacteria,\n",
    "* NET: neutrophile net,\n",
    "* Unknown intra: not classified objects for intracellurar probe,\n",
    "* Unknown extra: not classified objects for extracellular probe,\n",
    "* Labeling: Each class of objects are represented by a single number.\n",
    "\n",
    "In this tutorial we would like to create model that will predict to which class a given object belongs. Because of this we use \"Labeling\" as input to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_OF_ROI_LABELING=\"Labeling\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because first four classes that we want to distinguish are different phases of same cell type we have decided to use one hot encoding.\n",
    "Bellow is function that transform \"Labeling\" array into a 7 channel image. (*TODO dodać informacje o wykrywaniu krawędzi jeśli zadziała*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapalyzer_label_transform(labels):\n",
    "    one_hot = np.zeros((7,) + labels.shape, dtype=\"float32\")\n",
    "    for i in range(1, 6):\n",
    "        one_hot[i][labels == i] = 1\n",
    "    one_hot[6][labels == 8] = 1  # NET\n",
    "    one_hot[0][(labels == 0) | (labels > 8)] = 1  # Background\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_val(data_dir, patch_size, batch_size):\n",
    "    train_loader = get_partseg_loader(\n",
    "        data_dir,\n",
    "        patch_shape=(patch_size, patch_size),\n",
    "        batch_size=batch_size,\n",
    "        split=\"train\",\n",
    "        label_transform=trapalyzer_label_transform,\n",
    "        label_name=NAME_OF_ROI_LABELING,\n",
    "    )\n",
    "    val_loader = get_partseg_loader(\n",
    "        data_dir,\n",
    "        patch_shape=(patch_size, patch_size),\n",
    "        batch_size=batch_size,\n",
    "        split=\"test\",\n",
    "        label_name=NAME_OF_ROI_LABELING,\n",
    "        label_transform=trapalyzer_label_transform,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet2d(\n",
    "    in_channels=3,\n",
    "    out_channels=7,\n",
    "    depth=NETWORK_DEPTH,\n",
    "    initial_features=NETWORK_INITIAL_FEATURES,\n",
    ")\n",
    "train_loader, val_loader = get_train_and_val(data_path, PATCH_SIZE, BATCH_SIZE)\n",
    "\n",
    "MODEL_NAME = \"neutrofile_model\"\n",
    "\n",
    "trainer = torch_em.default_segmentation_trainer(\n",
    "    name=MODEL_NAME,\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    learning_rate=1e-4,\n",
    "    device=torch.device(\"cuda\"),\n",
    "    save_root=SAVE_ROOT,\n",
    ")\n",
    "trainer.fit(iterations=ITERATIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model exporting\n",
    "\n",
    "Used framework requires additional export steep to save model in bioimageio format. The export steep needs to be done on the same machine as training because of hardcoded path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_em.util.modelzoo import export_bioimageio_model\n",
    "\n",
    "DOCUMENTATION = \"Text with model documentation\"\n",
    "\n",
    "export_bioimageio_model(\n",
    "    os.path.join(SAVE_ROOT, \"checkpoints\", MODEL_NAME),\n",
    "    os.path.join(EXPORT_PATH, MODEL_NAME),\n",
    "    name=MODEL_NAME,\n",
    "    description=\"neutrofile model\",\n",
    "    authors=[{\"name\": \"Grzegorz Bokota\"}],\n",
    "    license=\"MIT\",\n",
    "    documentation=DOCUMENTATION,\n",
    "    git_repo=\"https://github.com/Czaki/PartSeg_bioimageio/\",\n",
    "    cite=\"\",\n",
    "    maintainers=[{\"github_user\": \"czaki\"}],\n",
    "    tags=[\n",
    "        \"2d\",\n",
    "        \"unet\",\n",
    "        \"fluorescence-light-microscopy\",\n",
    "        \"cells\",\n",
    "        \"pytorch\",\n",
    "        \"semantic-segmentation\",\n",
    "        \"ilastik\",\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
